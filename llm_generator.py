# llm_generator.py
import os
import json
import base64
import re # Add this import
import json
from typing import List, Dict, Any
from dotenv import load_dotenv
from pydantic import BaseModel, Field, ValidationError

# Google GenAI SDK imports
from google import genai
from google.genai import types
from google.genai.errors import APIError

# Load environment variables (API Key)
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# --- Pydantic Data Models (for structured LLM output) ---

class GeneratedFiles(BaseModel):
    """Schema for the files generated by the LLM.
    This class definition GeneratedFiles is a Pydantic model that defines
    a schema for the files generated by the LLM (Language Model).
    It has a single field named files, which is a dictionary mapping filenames
    (e.g., 'index.html', 'script.js') to their complete content as a string.
    The Field decorator is used to provide a description for the field."""
    # Reverting to the dictionary structure for simplicity
    files: Dict[str, str] = Field(
        description="A dictionary mapping filenames (e.g., 'index.html', 'script.js') to their complete content as a string."
    )


# --- Core LLM Module ---
"""
A brief explanation of what each method in the LLMCodeGenerator class does:

init: This is the constructor method that initializes an instance of the class.
It sets up the connection to the Gemini API for code generation by checking
if the API key is set in the environment variables, and if not, it raises a
ValueError. It also sets the model name for the API.

_process_attachments: This method takes a list of attachments and decodes any
base64-encoded attachments. It then formats the decoded content into a string
and returns it.

generate_app_files: This method takes a task request as input and generates
code files based on the task. It prepares the data and prompts for the LLM,
defines the structured output configuration, and defines the contents
including the system prompt. It then calls the Gemini API with robust error
catching, processes and validates the output using Pydantic, and returns the
generated files as a dictionary.

The generate_app_files method also handles various exceptions that may occur
during the process, such as API errors, JSON decoding errors, and validation
errors.
"""
class LLMCodeGenerator:
    """Manages connection to the Gemini API for code generation."""
    
    def __init__(self, model_name: str = 'gemini-2.5-flash'):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY is not set in .env.")
        
        self.client = genai.Client(api_key=GEMINI_API_KEY)
        self.model_name = model_name
        
    def _process_attachments(self, attachments: List[Dict[str, Any]]) -> str:
        """Decodes base64 attachments and formats them for the LLM prompt."""
        processed_data = []
        for attachment in attachments:
            url = attachment.get("url", "")
            name = attachment.get("name", "attachment")
            
            if url.startswith("data:"):
                try:
                    _, encoded_data = url.split(',', 1)
                except ValueError:
                    print(f"Error: Invalid data URI format for {name}")
                    continue

                try:
                    decoded_content = base64.b64decode(encoded_data).decode('utf-8')
                    sample_content = decoded_content[:1000] 
                    
                    processed_data.append(
                        f"## Attached File: {name}\n"
                        f"--- Content Sample ---\n"
                        f"{sample_content}\n"
                        f"----------------------\n"
                    )
                except Exception as e:
                    print(f"Error decoding attachment {name}: {e}")
        return "\n".join(processed_data)

    def generate_app_files(self, task_request: dict) -> Dict[str, str]:
        """Generates code files based on the task and returns them as a dictionary."""
        
        # 1. Prepare Data and Prompts
        attachments_context = self._process_attachments(task_request.get("attachments", []))
        brief = task_request.get("brief", "No detailed brief provided.")
        checks = task_request.get("checks", [])
        
        # System Prompt enforces the role and output constraints (reverted to dictionary instruction)
        system_prompt = (
            "You are an expert web developer specializing in generating clean, single-page "
            "web applications for simple tasks. Your output MUST be a single, valid JSON object "
            "that strictly adheres to the provided schema. The JSON object MUST contain a "
            "'files' dictionary where keys are the complete filenames (e.g., 'index.html', 'script.js') "
            "and values are the full content of those files as a string. "
            
            # --- ADDED REQUIREMENTS FOR EVALUATION COMPLIANCE ---
            "In addition to the main application files, you MUST ALWAYS include the following two files: "
            "1. **README.md**: A detailed README file specific to the application, describing its features and how to run it. "
            "2. **LICENSE**: The full and complete text of the MIT License. "
            
            # --- RETAINED STRICTNESS ---
            "\nDO NOT include any explanation, markdown formatting outside of the JSON block, or preamble."
        )

        user_prompt_text = (
            f"Generate all necessary files (at least index.html) to complete the following task:\n\n"
            f"**TASK BRIEF:** {brief}\n\n"
            f"**VERIFICATION CHECKS (for context):** {checks}\n\n"
            f"**ATTACHED DATA:**\n{attachments_context}\n\n"
            f"Ensure the generated code successfully meets the brief and is fully contained in the 'files' dictionary."
        )
        
        # 2. Define Structured Output Configuration (FIX: No response_schema)
        config = types.GenerateContentConfig(
            response_mime_type="application/json",
            # Removed response_schema to avoid the 'additionalProperties' error
        )

        # 3. Define Contents including the System Prompt (Final Fix)
        # We pass the system prompt as an initial "user" turn to guide the model.
        contents = [
            types.Content(
                parts=[types.Part.from_text(text=system_prompt)],
                role="user" 
            ),
            types.Content(
                parts=[types.Part.from_text(text=user_prompt_text)],
                role="user"
            )
        ]

        # 4. Call the Gemini API with robust error catching
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=contents,
                config=config,
            )
            
            # 5. Process and Validate Output using Pydantic (This still validates the structure)
            response_text = response.text 
            response_json = json.loads(response_text)
            validated_output = GeneratedFiles.model_validate(response_json)
            #print(response_json, response_text) # Debugging line to see raw response
            return validated_output.files

        except APIError as e:
            # We must handle APIError and ClientError gracefully, 
            # as ClientError may not have status_code
            if hasattr(e, 'status_code'):
                error_msg = f"Gemini API Error (Status: {e.status_code}): {e.message}"
            else:
                error_msg = f"Gemini API Error: {e.message}"
            
            raise RuntimeError(error_msg)
        except (json.JSONDecodeError, ValidationError) as e:
            print(f"Raw LLM Response (Debugging): {response_text[:100] + '...'}")
            raise RuntimeError(f"LLM returned invalid JSON structure or schema mismatch: {e}")
        except Exception as e:
            raise RuntimeError(f"An unexpected error occurred during LLM generation: {e}")


# --- Independent Test Block ---

if __name__ == "__main__":
    print("--- Testing LLMCodeGenerator Module ---")
    
    MOCK_REQUEST = {
        "email": "test@example.com",
        "secret": "dummy",
        "task": "sum-sales-data",
        "round": 1,
        "nonce": "test-nonce-ab12",
        "brief": "Create an HTML page that reads the attached CSV, sums the 'Sales' column, and displays the total in a <div id='total'> element.",
        "checks": ["js: document.querySelector(\"#total\").textContent == 1500"],
        "evaluation_url": "http://mock-evaluation-server.com/notify",
        "attachments": [
            { 
                "name": "data.csv", 
                "url": "data:text/csv;base64,UHJvZHVjdCxTYWxlcw5MYXB0b3AsMTAwMA5Nb25pdG9yLDUwMA==" 
            }
        ]
    }
    
    try:
        generator = LLMCodeGenerator() 
        
        print("\nSending request to Gemini...")
        generated_files = generator.generate_app_files(MOCK_REQUEST)
        
        print("\n--- LLM GENERATION SUCCESSFUL ---")
        print(f"Files Generated ({len(generated_files)}): {list(generated_files.keys())}")
        
        if 'index.html' in generated_files:
            content = generated_files['index.html']
            print("\n--- index.html Sample ---")
            print(content[:500] + "..." if len(content) > 500 else content)
            
    except RuntimeError as e:
        print(f"\n--- TEST FAILED ---")
        print(f"Reason: {e}")
    except ValueError as e:
        print(f"\n--- CONFIGURATION FAILED ---")
        print(f"Reason: {e}")